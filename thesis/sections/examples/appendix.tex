% !Mode:: "TeX:UTF-8"
% !TEX program  = xelatex
在这一节中，我们描述了详细的实验设置、额外的实验结果和完整的证明。
我们重新使用了从GNNAutoscale~\cite{fey2021gnnautoscale}中采用的部分代码；本文的代码可在： \url{https://github.com/Ziyang-Yu/SAT}。
请注意，为了提高可读性，对代码进行了重新组织。 

\section*{实验设置的细节}


所有的实验都是在AWS上的EC2 {\textbf{g4dn.metal}}虚拟机（VM）实例上进行的，该实例拥有8美元的NVIDIA T4 GPU，96美元的vCPUs，384美元~GB的主内存。其他重要信息，包括操作系统版本、Linux内核版本和CUDA版本，在表~ref{tab:版本}中进行了总结。为了公平比较，我们对所有10个框架，PipeGCN、PipeGCN$^{+}$、GNNAutoscale、GNNAutoscale$^{+}$、DIGEST、DIGEST$^{+}$、VRGCN、VRGCN$^{+}$、DIGEST-A和DIGEST-A$^{+}$使用相同的优化器（亚当）、学习率和图划分算法。
对于PipeGCN、GNNAutoscale、DIGEST、VRGCN、DIGEST-A独有的参数，如每个节点从每层采样的邻居数和层数，我们为PipeGCN$^{+}$、GNNAutoscale$^{+}$、DIGEST$^{+}$、VRGCN$^{+}$和DIGEST-A$^{+}$选择相同值。

这十个框架中的每一个都有一套专门针对该框架的参数；对于这些专属参数，我们对其进行调整，以达到最佳性能。请参考\textbf{small\_benchmark/conf}下的配置文件，了解所有模型和数据集的详细配置设置。



